{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fdbc7b",
   "metadata": {},
   "source": [
    "## import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178d5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01227351",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fe4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/processed/train_final.csv\")\n",
    "\n",
    "# Columns to drop\n",
    "drop_cols = [\n",
    "    \"PotentialFraud\", \n",
    "    \"Provider\"\n",
    "\n",
    "]\n",
    "\n",
    "# Features / target\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[\"PotentialFraud\"].astype(int)\n",
    "\n",
    "# Train / validation / test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd151ec",
   "metadata": {},
   "source": [
    "## basic Evaluation to choose a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb750f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_for_recall(y_true, y_probs, target_recall=0.90):\n",
    "    prec, rec, thresh = precision_recall_curve(y_true, y_probs)\n",
    "    \n",
    "    # recall is in descending order, find highest threshold where recall >= target\n",
    "    valid_idx = np.where(rec >= target_recall)[0]\n",
    "    \n",
    "    if len(valid_idx) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # get the last valid index (highest threshold with recall >= target)\n",
    "    # thresh has one fewer element than prec/rec, so cap at len(thresh)-1\n",
    "    best_idx = min(valid_idx[-1], len(thresh) - 1)\n",
    "    return thresh[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e028a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_threshold(name, y_true, y_probs, threshold):\n",
    "    \"\"\"Evaluate model at a specific threshold, print metrics, and return a summary dict.\"\"\"\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_probs)\n",
    "    avg_prec = average_precision_score(y_true, y_probs)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    result = {\n",
    "        \"model\": name,\n",
    "        \"threshold\": float(threshold),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1\": float(f1),\n",
    "        \"roc_auc\": float(roc_auc),\n",
    "        \"avg_precision\": float(avg_prec),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} @ threshold={threshold:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}, AP: {avg_prec:.4f}\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90934ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_precision_with_minimum_recall(y_true, prob, target_recall=0.92, steps=2000):\n",
    "    thresholds = np.linspace(0, 1, steps)\n",
    "    best_thresh, best_prec, best_rec = 0.0, 0.0, 0.0\n",
    "    for t in thresholds:\n",
    "        preds = (prob >= t).astype(int)\n",
    "        prec = precision_score(y_true, preds, zero_division=0)\n",
    "        rec = recall_score(y_true, preds)\n",
    "        if rec >= target_recall and prec > best_prec:\n",
    "            best_prec, best_rec, best_thresh = prec, rec, t\n",
    "    return best_thresh, best_prec, best_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb1b80",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d38db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio: 9.686419753086419\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "\n",
      "Best GB params: {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 250, 'subsample': 0.8}\n",
      "Best CV AP: 0.9440819180776305\n",
      "\n",
      "Best GB params: {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 250, 'subsample': 0.8}\n",
      "Best CV AP: 0.9440819180776305\n",
      "\n",
      "Optimal Threshold: 0.6208104052026012\n",
      "Precision: 0.5340909090909091\n",
      "Recall: 0.9215686274509803\n",
      "GB Calibrated Optimized @ threshold=0.6208\n",
      "Precision: 0.5341, Recall: 0.9216, F1: 0.6763, ROC AUC: 0.9661, AP: 0.7071\n",
      "Confusion matrix:\n",
      "[[449  41]\n",
      " [  4  47]]\n",
      "\n",
      "Optimal Threshold: 0.6208104052026012\n",
      "Precision: 0.5340909090909091\n",
      "Recall: 0.9215686274509803\n",
      "GB Calibrated Optimized @ threshold=0.6208\n",
      "Precision: 0.5341, Recall: 0.9216, F1: 0.6763, ROC AUC: 0.9661, AP: 0.7071\n",
      "Confusion matrix:\n",
      "[[449  41]\n",
      " [  4  47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'GB Calibrated Optimized',\n",
       " 'threshold': 0.6208104052026012,\n",
       " 'precision': 0.5340909090909091,\n",
       " 'recall': 0.9215686274509803,\n",
       " 'f1': 0.6762589928057554,\n",
       " 'roc_auc': 0.9660864345738296,\n",
       " 'avg_precision': 0.707050604082991,\n",
       " 'confusion_matrix': [[449, 41], [4, 47]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# HANDLE IMBALANCE\n",
    "# ============================================================\n",
    "scale = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "sample_weights = np.where(y_train == 1, scale, 1)\n",
    "print(\"Class imbalance ratio:\", scale)\n",
    "\n",
    "# ============================================================\n",
    "# SAFE HYPERPARAMETER GRID (prevents overfitting)\n",
    "# ============================================================\n",
    "gb_base = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid_gb = {\n",
    "    \"n_estimators\": [150, 200, 250],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"subsample\": [0.7, 0.8],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    gb_base,\n",
    "    param_grid_gb,\n",
    "    scoring=\"average_precision\",   # BEST for fraud\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_gb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "print(\"\\nBest GB params:\", grid_gb.best_params_)\n",
    "print(\"Best CV AP:\", grid_gb.best_score_)\n",
    "\n",
    "gb_best = grid_gb.best_estimator_\n",
    "\n",
    "# ============================================================\n",
    "# CALIBRATION\n",
    "# ============================================================\n",
    "gb_cal = CalibratedClassifierCV(gb_best, method=\"isotonic\", cv=3)\n",
    "gb_cal.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "gb_probs = gb_cal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ============================================================\n",
    "# BEST PRECISION while recall â‰¥ 0.92\n",
    "# ============================================================\n",
    "def best_precision_with_minimum_recall(y_true, prob, target_recall=0.92):\n",
    "    thresholds = np.linspace(0, 1, 2000)\n",
    "    best_thresh, best_prec, best_rec = 0, 0, 0\n",
    "\n",
    "    for t in thresholds:\n",
    "        preds = (prob >= t).astype(int)\n",
    "        prec = precision_score(y_true, preds, zero_division=0)\n",
    "        rec = recall_score(y_true, preds)\n",
    "\n",
    "        if rec >= target_recall and prec > best_prec:\n",
    "            best_prec = prec\n",
    "            best_rec = rec\n",
    "            best_thresh = t\n",
    "\n",
    "    return best_thresh, best_prec, best_rec\n",
    "\n",
    "\n",
    "thresh, best_prec, best_rec = best_precision_with_minimum_recall(\n",
    "    y_val, gb_probs, target_recall=0.92\n",
    ")\n",
    "\n",
    "print(\"\\nOptimal Threshold:\", thresh)\n",
    "print(\"Precision:\", best_prec)\n",
    "print(\"Recall:\", best_rec)\n",
    "\n",
    "gb_result = evaluate_with_threshold(\"GB Calibrated Optimized\", y_val, gb_probs, thresh)\n",
    "gb_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9139c0",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619e299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio (XGB): 9.69\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "\n",
      "Best XGB params: {'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 6, 'n_estimators': 400, 'subsample': 0.8}\n",
      "Best XGB CV AP Score: 0.9442\n",
      "\n",
      "Best XGB params: {'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 6, 'n_estimators': 400, 'subsample': 0.8}\n",
      "Best XGB CV AP Score: 0.9442\n",
      "\n",
      "XGB optimal threshold: 0.5653, precision: 0.5402, recall: 0.9216\n",
      "XGBoost (Calibrated) @ threshold=0.5653\n",
      "Precision: 0.5402, Recall: 0.9216, F1: 0.6812, ROC AUC: 0.9635, AP: 0.6970\n",
      "Confusion matrix:\n",
      "[[450  40]\n",
      " [  4  47]]\n",
      "\n",
      "XGB optimal threshold: 0.5653, precision: 0.5402, recall: 0.9216\n",
      "XGBoost (Calibrated) @ threshold=0.5653\n",
      "Precision: 0.5402, Recall: 0.9216, F1: 0.6812, ROC AUC: 0.9635, AP: 0.6970\n",
      "Confusion matrix:\n",
      "[[450  40]\n",
      " [  4  47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'XGBoost (Calibrated)',\n",
       " 'threshold': 0.5652826413206603,\n",
       " 'precision': 0.5402298850574713,\n",
       " 'recall': 0.9215686274509803,\n",
       " 'f1': 0.6811594202898551,\n",
       " 'roc_auc': 0.9635054021608643,\n",
       " 'avg_precision': 0.6969718380402277,\n",
       " 'confusion_matrix': [[450, 40], [4, 47]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalance handling\n",
    "scale = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "sample_weights = np.where(y_train == 1, scale, 1)\n",
    "print(f\"Class imbalance ratio (XGB): {scale:.2f}\")\n",
    "\n",
    "xgb_base = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb_base,\n",
    "    param_grid_xgb,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "print(f\"\\nBest XGB params: {grid_xgb.best_params_}\")\n",
    "print(f\"Best XGB CV AP Score: {grid_xgb.best_score_:.4f}\")\n",
    "\n",
    "# Use best estimator directly\n",
    "xgb_best = grid_xgb.best_estimator_\n",
    "\n",
    "# Calibrate\n",
    "xgb_cal = CalibratedClassifierCV(xgb_best, method=\"isotonic\", cv=3)\n",
    "xgb_cal.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Get probabilities\n",
    "xgb_probs = xgb_cal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Find threshold for 92% recall\n",
    "xgb_thresh, xgb_prec, xgb_rec = best_precision_with_minimum_recall(y_val, xgb_probs, target_recall=0.92)\n",
    "print(f\"\\nXGB optimal threshold: {xgb_thresh:.4f}, precision: {xgb_prec:.4f}, recall: {xgb_rec:.4f}\")\n",
    "\n",
    "# Evaluate with threshold\n",
    "xgb_result = evaluate_with_threshold(\"XGBoost (Calibrated)\", y_val, xgb_probs, xgb_thresh)\n",
    "\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d911c14",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb52286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio (LR): 9.69\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "Best LR params: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best CV AP: 0.9350319277599715\n",
      "\n",
      "Best LR params: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best CV AP: 0.9350319277599715\n",
      "\n",
      "LR optimal threshold: 0.3091545772886443 precision: 0.30128205128205127 recall: 0.9215686274509803\n",
      "LogReg (Calibrated Optimized) @ threshold=0.3092\n",
      "Precision: 0.3013, Recall: 0.9216, F1: 0.4541, ROC AUC: 0.9459, AP: 0.7336\n",
      "Confusion matrix:\n",
      "[[381 109]\n",
      " [  4  47]]\n",
      "\n",
      "LR optimal threshold: 0.3091545772886443 precision: 0.30128205128205127 recall: 0.9215686274509803\n",
      "LogReg (Calibrated Optimized) @ threshold=0.3092\n",
      "Precision: 0.3013, Recall: 0.9216, F1: 0.4541, ROC AUC: 0.9459, AP: 0.7336\n",
      "Confusion matrix:\n",
      "[[381 109]\n",
      " [  4  47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'LogReg (Calibrated Optimized)',\n",
       " 'threshold': 0.3091545772886443,\n",
       " 'precision': 0.30128205128205127,\n",
       " 'recall': 0.9215686274509803,\n",
       " 'f1': 0.45410628019323673,\n",
       " 'roc_auc': 0.9458783513405362,\n",
       " 'avg_precision': 0.7336427296275101,\n",
       " 'confusion_matrix': [[381, 109], [4, 47]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression: use class_weight & sample_weight\n",
    "scale = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "sample_weights = np.where(y_train == 1, scale, 1)\n",
    "print(\"Class imbalance ratio (LR):\", round(scale,2))\n",
    "\n",
    "log_base = LogisticRegression(max_iter=5000, random_state=42, solver='liblinear')\n",
    "\n",
    "param_grid_log = {\n",
    "    \"C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "grid_log = GridSearchCV(\n",
    "    log_base,\n",
    "    param_grid_log,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_log.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "print(\"\\nBest LR params:\", grid_log.best_params_)\n",
    "print(\"Best CV AP:\", grid_log.best_score_)\n",
    "\n",
    "log_best = grid_log.best_estimator_\n",
    "\n",
    "log_cal = CalibratedClassifierCV(log_best, method=\"isotonic\", cv=3)\n",
    "log_cal.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "log_probs = log_cal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "log_thresh, log_prec, log_rec = best_precision_with_minimum_recall(y_val, log_probs, target_recall=0.92)\n",
    "print(\"\\nLR optimal threshold:\", log_thresh, \"precision:\", log_prec, \"recall:\", log_rec)\n",
    "\n",
    "evaluate_with_threshold(\"LogReg (Calibrated Optimized)\", y_val, log_probs, log_thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4b2d8",
   "metadata": {},
   "source": [
    "## RandomForest (Main model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06ad0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best RF params: {'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best RF CV AP Score: 0.7217\n",
      "\n",
      "Best RF params: {'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best RF CV AP Score: 0.7217\n",
      "\n",
      "Threshold for 90% recall: 0.2014\n",
      "Random Forest (Calibrated) @ threshold=0.2014\n",
      "Precision: 0.5750, Recall: 0.9020, F1: 0.7023, ROC AUC: 0.9677, AP: 0.7381\n",
      "Confusion matrix:\n",
      "[[456  34]\n",
      " [  5  46]]\n",
      "\n",
      "Threshold for 90% recall: 0.2014\n",
      "Random Forest (Calibrated) @ threshold=0.2014\n",
      "Precision: 0.5750, Recall: 0.9020, F1: 0.7023, ROC AUC: 0.9677, AP: 0.7381\n",
      "Confusion matrix:\n",
      "[[456  34]\n",
      " [  5  46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Random Forest (Calibrated)',\n",
       " 'threshold': 0.20135756056808687,\n",
       " 'precision': 0.575,\n",
       " 'recall': 0.9019607843137255,\n",
       " 'f1': 0.7022900763358778,\n",
       " 'roc_auc': 0.9677470988395358,\n",
       " 'avg_precision': 0.7381196814740336,\n",
       " 'confusion_matrix': [[456, 34], [5, 46]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_base = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf_base,\n",
    "    param_grid_rf,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest RF params: {grid_rf.best_params_}\")\n",
    "print(f\"Best RF CV AP Score: {grid_rf.best_score_:.4f}\")\n",
    "\n",
    "# Use best estimator directly\n",
    "rf_best = grid_rf.best_estimator_\n",
    "\n",
    "# Calibrate\n",
    "rf_cal = CalibratedClassifierCV(rf_best, method=\"isotonic\", cv=3)\n",
    "rf_cal.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "rf_probs = rf_cal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Find threshold for 90% recall\n",
    "rf_threshold = find_threshold_for_recall(y_val, rf_probs, target_recall=0.90)\n",
    "print(f\"\\nThreshold for 90% recall: {rf_threshold:.4f}\")\n",
    "\n",
    "# Evaluate with threshold\n",
    "rf_result = evaluate_with_threshold(\"Random Forest (Calibrated)\", y_val, rf_probs, rf_threshold)\n",
    "\n",
    "\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca008c5",
   "metadata": {},
   "source": [
    "## Test data & prediction CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce88c6",
   "metadata": {},
   "source": [
    "## FINAL MODEL: Random Forest with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a597e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FINAL MODEL EVALUATION ON TEST SET\n",
      "==================================================\n",
      "\n",
      "Using threshold from validation: 0.2014\n",
      "Random Forest (Final - Test) @ threshold=0.2014\n",
      "Precision: 0.5114, Recall: 0.9000, F1: 0.6522, ROC AUC: 0.9722, AP: 0.8370\n",
      "Confusion matrix:\n",
      "[[448  43]\n",
      " [  5  45]]\n",
      "\n",
      "==================================================\n",
      "TEST SET RESULTS\n",
      "==================================================\n",
      "Threshold (from validation): 0.2014\n",
      "Test Precision: 0.5114\n",
      "Test Recall: 0.9000\n",
      "Test F1: 0.6522\n",
      "Test ROC AUC: 0.9722\n",
      "Test AP: 0.8370\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"FINAL MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nUsing threshold from validation: {rf_threshold:.4f}\")\n",
    "\n",
    "# Get test probabilities using the SAME model from validation\n",
    "test_probs = rf_cal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply the validation threshold\n",
    "test_preds = (test_probs >= rf_threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "test_result = evaluate_with_threshold(\"Random Forest (Final - Test)\", y_test, test_probs, rf_threshold)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Threshold (from validation): {rf_threshold:.4f}\")\n",
    "print(f\"Test Precision: {test_result['precision']:.4f}\")\n",
    "print(f\"Test Recall: {test_result['recall']:.4f}\")\n",
    "print(f\"Test F1: {test_result['f1']:.4f}\")\n",
    "print(f\"Test ROC AUC: {test_result['roc_auc']:.4f}\")\n",
    "print(f\"Test AP: {test_result['avg_precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593e148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved to: c:\\Users\\omarh\\Fraud Detection\\HealthCare-Insurance-Fraud-Detection\\models\n",
      "Saved: gb_calibrated.joblib\n",
      "Saved: xgb_calibrated.joblib\n",
      "Saved: log_calibrated.joblib\n",
      "Saved: xgb_calibrated.joblib\n",
      "Saved: log_calibrated.joblib\n",
      "Saved: rf_calibrated.joblib\n",
      "Saved: rf_calibrated.joblib\n"
     ]
    }
   ],
   "source": [
    "# Saving models for evaluation\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "models_dir = os.path.abspath(os.path.join(\"..\", \"models\"))\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "print(f\"Models will be saved to: {models_dir}\")\n",
    "\n",
    "# Save calibrated models\n",
    "joblib.dump(gb_cal, os.path.join(models_dir, \"gb_calibrated.joblib\"))\n",
    "print(\"Saved: gb_calibrated.joblib\")\n",
    "\n",
    "joblib.dump(xgb_cal, os.path.join(models_dir, \"xgb_calibrated.joblib\"))\n",
    "print(\"Saved: xgb_calibrated.joblib\")\n",
    "\n",
    "joblib.dump(log_cal, os.path.join(models_dir, \"log_calibrated.joblib\"))\n",
    "print(\"Saved: log_calibrated.joblib\")\n",
    "\n",
    "joblib.dump(rf_cal, os.path.join(models_dir, \"rf_calibrated.joblib\"))\n",
    "print(\"Saved: rf_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8e316",
   "metadata": {},
   "source": [
    "# LOAD EXTERNAL TEST DATA & GENERATE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd74cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External test data shape: (1353, 38)\n",
      "Training features: 38\n",
      "\n",
      "Predictions generated for 1353 providers\n",
      "Predicted Fraud: 202 (14.93%)\n",
      "Predicted Non-Fraud: 1151 (85.07%)\n"
     ]
    }
   ],
   "source": [
    "# Load external test data (unlabeled - for submission)\n",
    "test_df = pd.read_csv(\"../data/processed/test_final.csv\")\n",
    "\n",
    "# Keep Provider for output\n",
    "providers = test_df[\"Provider\"]\n",
    "\n",
    "# Drop same columns as training\n",
    "X_external = test_df.drop(columns=[\"Provider\"])\n",
    "\n",
    "# If PotentialFraud exists in test, drop it (for prediction)\n",
    "if \"PotentialFraud\" in X_external.columns:\n",
    "    X_external = X_external.drop(columns=[\"PotentialFraud\"])\n",
    "\n",
    "print(f\"External test data shape: {X_external.shape}\")\n",
    "print(f\"Training features: {X_train.shape[1]}\")\n",
    "\n",
    "# Ensure columns match training data\n",
    "missing_cols = set(X_train.columns) - set(X_external.columns)\n",
    "extra_cols = set(X_external.columns) - set(X_train.columns)\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns in test data: {missing_cols}\")\n",
    "if extra_cols:\n",
    "    print(f\"Extra columns in test data (will be dropped): {extra_cols}\")\n",
    "    X_external = X_external.drop(columns=list(extra_cols))\n",
    "\n",
    "# Reorder columns to match training\n",
    "X_external = X_external[X_train.columns]\n",
    "\n",
    "# Generate predictions using rf_cal and rf_threshold\n",
    "external_probs = rf_cal.predict_proba(X_external)[:, 1]\n",
    "external_preds = (external_probs >= rf_threshold).astype(int)\n",
    "\n",
    "print(f\"\\nPredictions generated for {len(external_preds)} providers\")\n",
    "print(f\"Predicted Fraud: {external_preds.sum()} ({100*external_preds.mean():.2f}%)\")\n",
    "print(f\"Predicted Non-Fraud: {(1-external_preds).sum()} ({100*(1-external_preds.mean()):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f04da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: ../data/predictions.csv\n",
      "\n",
      "Submission shape: (1353, 3)\n",
      "\n",
      "Submission preview:\n",
      "   Provider  PotentialFraud  FraudProbability\n",
      "0  PRV51002               0          0.004219\n",
      "1  PRV51006               0          0.002362\n",
      "2  PRV51009               0          0.029196\n",
      "3  PRV51010               0          0.018108\n",
      "4  PRV51018               0          0.012618\n",
      "5  PRV51019               0          0.002362\n",
      "6  PRV51020               0          0.022311\n",
      "7  PRV51022               0          0.071145\n",
      "8  PRV51028               0          0.002362\n",
      "9  PRV51033               0          0.020796\n",
      "\n",
      "==================================================\n",
      "PREDICTION SUMMARY\n",
      "==================================================\n",
      "Total Providers: 1353\n",
      "Predicted Fraudulent: 202\n",
      "Predicted Non-Fraudulent: 1151\n",
      "Fraud Rate: 14.93%\n"
     ]
    }
   ],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"Provider\": providers,\n",
    "    \"PotentialFraud\": external_preds,\n",
    "    \"FraudProbability\": external_probs\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../data/predictions.csv\"\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {output_path}\")\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Providers: {len(submission)}\")\n",
    "print(f\"Predicted Fraudulent: {submission['PotentialFraud'].sum()}\")\n",
    "print(f\"Predicted Non-Fraudulent: {(1 - submission['PotentialFraud']).sum()}\")\n",
    "print(f\"Fraud Rate: {100 * submission['PotentialFraud'].mean():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
